\title{Dynamic Programming -- Infinite Horizon}
\author{William M Volckmann II}
\documentclass[12pt]{article}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{xifthen}
\usepackage{titlesec}
\usepackage[normalem]{ulem}
\usepackage[final]{pdfpages}
%\usepackage[top=1.25in, left=1.25in, right=1.25in]{geometry}

\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Chi}{\mathcal{X}}
\newcommand{\grad}{\nabla}
\newcommand{\B}{\beta}
\newcommand{\BH}{\hat{\beta}}
\newcommand{\bh}{\hat{\beta}}
\newcommand{\sumn}{\sum_{i=1}^n}
\newcommand{\crit}{c_{\alpha}}
\newcommand{\given}{\; | \;}
\newcommand{\xbar}{\bar{X}_n}
\newcommand{\asim}{\overset{a}{\sim}}
\newcommand{\Lindent}{\hspace{.4cm} \Longrightarrow \hspace{.4cm}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator*{\plim}{plim}
\DeclareMathOperator{\rank}{rank}

\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\setenumerate{itemsep=-1pt, label=\textbf{(\alph*)}}

\begin{document}


\maketitle
\onehalfspace
\input{disclaimer}




\section{Infinite Horizon}
Let's begin by considering the Cobb-Douglas case where $f(k)=k^{\alpha}$ and $u(c)=\ln(c)$. Recall the law of motion of capital from the finite horizon problem,
\begin{equation}
	k_{t+1} = \alpha \beta \frac{ 1 - (\alpha \beta)^{T -t}}{ 1 - (\alpha \beta)^{T -t +1}}k^{\alpha}_{t}. \label{cdlomoc} 
\end{equation}
As $T$ becomes very large, then because $0 < \alpha \beta < 1$, it follows that the coefficient in front of $k_t^{\alpha}$ will become very close to $\alpha \beta$ for most of the sequence. And at this point, we might wonder why we cannot just take the limit as $T$ goes to infinity as the solution for the infinite horizon problem. Doing so would give an solution of
	\[k_{t+1} = \alpha \beta k_t^{\alpha}.	\]

Well, it turns out we \emph{can} just take the limit for the infinite horizon problem, and this is true in general. To prove it, one must first establish that  interchanging $\max$ and $\lim$ operators  is kosher, and this is actually rather difficult to show. 

So nuts to that. Let's try a different approach. The limit suggests that there is a fixed rule that is used in every period. In this example, the rule seems like it should be to take a fixed proportion of your available capital to the next period, in particular, $\alpha \beta$ of it. More generally, we can conjecture that there is a fixed ``savings function'' or \textbf{policy function} of the form
	\[	k_{t+1} = g(k_t).	\]
This is fairly intuitive. The social planner problem looks the same from any given period; the only meaningful difference is the capital stock in each particular period. 

But finding that savings function could be challenging. There isn't any general way we can do it from looking at first order and boundary conditions. The change of variable $z_t = k_t / k_{t-1}^{\alpha}$ is specific to the example. So we need a new approach entirely. 

Let's try thinking in terms of only \emph{today} and \emph{tomorrow}, in particular, of choosing consumption today $c_0$ and tomorrow's beginning-of-period capital $k_1$. Let $v(\cdot)$ be the \textbf{value function}, supposing one exists, that gives the value of the maximized objective function; it's not unlike an indirect utility function, as far as interpretation goes. So $v(k_0)$ is the level of utility we'd get from solving the planner's problem, for instance. Or, given some beginning-of-period capital stock $k_1$ in period 1, the best that could be done from that point on is $v(k_1)$. Using this, we can rewrite the social planner's problem as 
\begin{align*}
	&\max_{c_0, k_1} \left[U(c_0) + \beta v(k_1) \right]\\
	\text{s.t. }\;\; &c_0 + k_1 \leq f(k_0),\\
	&c_0, k_1 \geq 0, \;\; k_0>0 \text{ given}.
\end{align*}

Of course, we don't actually know what $v(\cdot)$ is. All we really know about it is that is solves the maximization problem. That is,
	\[v(k_0) = \max_{0 \leq k_1 \leq f(k_0)} \left \{ U\big( f(k_0) - k_1 \big) + \beta v(k_1) \right \}.	\]
Now that we are dealing with only two indices, we can adopt the more convenient $k$ for current and $k'$ for next-period. Also, recall our conjecture (which is actually true) that there exists a time-invariant policy rule $k'=g(k)$ that is followed in optimum. Thus, we can actually write the maximization problem as 
\begin{equation}
	v(k) = U\big( f(k) - g(k) \big) + \beta v\big( g(k) \big)  \; \; \text{ s.t. } \;\; 0 \leq g(k) \leq f(k) . \label{bellman}
\end{equation}
Equation (\ref{bellman}) is called the \textbf{Bellman equation}. Notice that we are able to drop the $\max$ operator since $g(k)$ is defined to be the optimal policy rule -- the fact that we are using it means we will attain the maximum.

So we have one equation with an unknown function $v(\cdot)$, which we call a \textbf{functional equation}. Optimizing such problems via functional equations is what constitutes \textbf{dynamic programming}. This will be our bread and butter. 

Let's suppose that $v(\cdot)$ is differentiable and that there is an interior solution. Then the first order condition (differentiate with respect to $g(k)$ and set equal to zero) is
\begin{equation}
	U_{g(k)}'\big( f(k) - g(k) \big) = \beta v_{g(k)}'\big( g(k) \big). \label{bellmanfoc}
\end{equation}
To find the envelope condition, differentiate with respect to $k$ to get
\[
	v_{k}'(k) = U_{f(k)}'\big( f(k)-g(k)\big)f_k'(k) - U_{g(k)}'\big( f(k)-g(k)\big)g_k'(k) + \beta v_{g(k)}'\big(g(k)\big)g_k'(k).
\]
Notice that equation (\ref{bellmanfoc}) implies that the latter two terms sum to zero. Thus, the envelope condition is
\begin{equation}
	v'(k)=U_{f(k)}'\big( f(k)-g(k)\big)f_k'(k). \label{bellmanec}
\end{equation}
Stokey and Lucas give interpretations for  conditions (\ref{bellmanfoc}) and (\ref{bellmanec}), although I don't find either to particularly intuitive.
\begin{quote}
	The first of these conditions equates the marginal utility of consuming current output to the marginal utility of allocating it to capital and enjoying augmented consumption next period. The second condition states that the marginal value of current capital, in terms of total discounted utility, is given by the marginal utility of using the capital in current production and allocating its return to current consumption.
\end{quote}


\section{Example: Cobb-Douglas Revisited}

Let's try to calculate $v(\cdot)$ given the conjecture $g(k)= \alpha \beta k^{\alpha}$. The value function can be written as
\begin{align*}
	 v(k_0) &= \ln( k_0^{\alpha} - \alpha \beta k_0^{\alpha}) + \beta \ln( k_1^{\alpha} - \alpha \beta k_1^{\alpha}) + \beta^2 \ln( k_2^{\alpha} - \alpha \beta k_2^{\alpha}) + ...\\
	 	&= \alpha \ln(k_0) + \ln(1 - \alpha \beta) + \alpha \beta \ln(k_1) + \beta\ln(1 - \alpha \beta) + ... \\
		& = [\alpha \ln(k_0) + \alpha \beta \ln(k_1) + \alpha \beta^2 \ln(k_2) + ...] + \ln(1 - \alpha \beta)(1 + \beta + \beta^2 + ... )\\
		& = [\alpha \ln(k_0) + \alpha \beta \ln(k_1) + \alpha \beta^2 \ln(k_2) + ...] + \frac{1}{1 - \beta}\ln(1 - \alpha \beta).
\end{align*}
The sum involving the $k$ terms looks like it could be problematic. It would be really nice if we could combine those logarithms, wouldn't it? Well, by using our conjectured policy function $g(k)=\alpha \beta k^{\alpha}$, we can write each term in the sum in terms of $k_0$. For example, the first four terms in the sum are
\begin{align*}
&\hspace{.5cm}	\alpha \ln(k_0)  \\
&+ \alpha^2 \beta \ln(k_0) &&+ \alpha \beta \ln(\alpha \beta)  \\
&+ \alpha^3 \beta^2 \ln( k_0) &&+  \alpha \beta^2 \ln(\alpha \beta) &&+ \alpha^2 \beta^2 \ln(\alpha \beta)  \\
&+ \alpha^4 \beta^3 \ln( k_0) &&+ \alpha \beta^3 \ln(\alpha \beta) &&+ \alpha^2 \beta^3 \ln(\alpha \beta ) &&+ \alpha^3 \beta^3 \ln(\alpha \beta)  \\
&+ \hdots && + \hdots  && + \hdots && + \hdots && + \hdots
\end{align*}

What we're going to do is take each column as its own series. The first column, for instance, results in
	\[\frac{\alpha}{1 - \alpha \beta} \ln(k_0), 	\]
which takes care of the $k_0$ terms. The rest of them all have $\ln(\alpha \beta)$ involved. The second, third, and fourth columns give respective sums of
	\[	 \ln(\alpha \beta)\frac{\alpha \beta}{1 - \beta}, \indent	 \ln(\alpha \beta)\frac{\alpha^2 \beta^2}{1 - \beta}, \indent \ln(\alpha \beta)\frac{\alpha^3 \beta^3}{1 - \beta}, \]
and so on. There are an infinite number of columns, so \emph{these} constitute a series, the sum of which evaluates to
	\[\frac{ \ln(\alpha \beta)}{1 - \beta} \frac{\alpha \beta}{1 - \alpha \beta}.	\]
Great, so let's combine everything into
\begin{equation}
	v(k_0) = \frac{\alpha}{1 - \alpha \beta} \ln(k_0) + \frac{1}{1 - \beta}\left( \frac{\alpha \beta}{1 - \alpha \beta}\ln(\alpha \beta) + \ln(1 - \alpha \beta)	 \right). \label{cobbvaluek_0}
\end{equation}
Note that $v(k)$ takes the form $A \ln(k) + B$. This will show up again later.

Anyway, consider our newly found value function in terms of the Bellman equation. In particular,
\begin{equation}
	v(k) = \ln\big( k^{\alpha} - \alpha \beta k^{\alpha} \big) + \beta \left[ A \ln(\alpha \beta k^{\alpha}) + B \right ]. \label{cobbbellman}
\end{equation}
Let's see if it satisfies the first order condition and the envelope condition. For the first order condition, we want to differentiate with respect to $\alpha \beta k^{\alpha}$, resulting in
\[ \frac{1}{k^{\alpha} - \alpha \beta k^{\alpha}} = \frac{\beta A}{\alpha \beta k^{\alpha}} \Lindent \frac{\alpha k^{\alpha}}{k^{\alpha} - \alpha \beta k^{\alpha}} = \frac{\alpha}{1 - \alpha \beta } =A.	\]
Okay, so the first-order condition checks out -- this is indeed how $A$ is defined in equation (\ref{cobbvaluek_0}). Now to test the envelope condition, we want to take the derivative with respect to $k$, which results in
\begin{align*}	
	v'(k) &= \frac{1}{k^{\alpha} - \alpha \beta k^{\alpha}}(\alpha k^{\alpha - 1} - \alpha^2 \beta k^{\alpha - 1}) + \frac{\beta A}{\alpha \beta k^{\alpha}}\alpha^2 \beta k^{\alpha - 1}	\\
	& = \frac{\alpha}{k(1 - \alpha \beta) }(1 - \alpha \beta ) + \frac{ A}{k}\alpha \beta \\
	& = \frac{\alpha}{k(1 - \alpha \beta) }(1 - \alpha \beta ) + \frac{\alpha}{1 - \alpha \beta }\frac{\alpha \beta}{k} \\
	&= \frac{\alpha}{(1 - \alpha \beta)k}.
\end{align*}
This must equal the result from equation (\ref{bellmanec}), which gives
\begin{align*}
	U_{f(k)}'\big( f(k)-g(k)\big)f_k'(k) 	&= \frac{1}{k^{\alpha} - \alpha \beta k^{\alpha}} \alpha k^{\alpha - 1}\\
	&= \frac{\alpha}{k(1 - \alpha \beta) }.
\end{align*}
So both the first order condition and the envelope condition are satisfied. Hooray!\\

The nice thing about this Cobb-Douglas example is that we can solve for $g(\cdot)$ just using a pencil some paper if we're vigilant enough, thus giving us the optimal sequence of capital. Unfortunately, most of the time we will not be able to derive an explicit, closed-form solution. We will often have to resort to approximating $g(\cdot)$. 

Sometimes we'll be able to deduce qualitative features of the policy function that are valid under varying assumptions on $f(\cdot)$ and $U(\cdot)$. In such a case we can characterize $g(\cdot)$ and thus establish solutions for the capital sequence. For instance, suppose the policy function says to save a constant fraction of $f(k)$, that is, $g(k)=sf(k)$ where $s>0$. The policy function will inherit properties of $f(k)$, in particular, i tis strictly increasing and strictly concave, continuously differentiable, comes from the origin, and is strictly positive. If we draw $g(k)$ along with a $45^{\cdot}$ line, we can trace through a trajectory of $k_t$. Granted, we won't know the precise values of any $k_t$, but we can still that it will gravitate to a steady state and furthermore, one of the steady-states (the unstable one) will be at the origin.



\section{Successive Approximations}

Consider again the functional equation
\begin{align}
	v(k) = \max_{c,k'} [U(c) + \beta v(k')] \label{functionaleq}\\
	\text{ s.t. } c + k' \leq f(k), \nonumber \\
	c,k' \geq 0. \nonumber
\end{align}
The functions $U(\cdot)$ and $f(\cdot)$ are given are we know their specific forms, whereas $v(\cdot)$ is unknown. We'd like to be able to prove the existence of $v(\cdot)$ and deduce its properties given those of $U(\cdot)$ and $f(\cdot)$. 

The classical approach to this problem is the \textbf{method of successive approximations}. It involves making an initial guess that a specific function, call it $v_0(\cdot)$, satisfies equation (\ref{functionaleq}). Then we define a new function,
	\[v_1(k) = \max_{0 \leq k' \leq f(k)} \left\{U\big( f(k) - k' \big) + \beta v_0(k') \right\}.	\]
If $v_1(k)=v_0(k)$ for all $k \geq 0$, then it must be that $v_0$ is a solution to equation (\ref{functionaleq}). This is because $v_1(k)$ is defined as the maximum utility; so if $v_0(k)$ also achieves the maximum utility, it must be a solution.

But usually $v_1 \neq v_2$. In this case, we use $v_1$ as a new guess and define the sequence of functions $\{v_n\}$ recursively by
	\[v_{n+1}(k) = \max_{0 \leq k' \leq f(k)} \left\{U\big( f(k) - k' \big) + \beta v_n(k') \right\}, \;\; n \in \N.	\]
The idea is that as $n$ increases, the successive approximations $v_n$ get closer to a function that actually satisfies 	equation (\ref{functionaleq}). If it can be shown that the limit of $v_n$ is the same for any initial guess $v_0$, then this limit is the only function satisfying equation (\ref{functionaleq}). 

To see this, suppose we begin by choosing some feasible capital accumulation policy $g_0$ that satisfies $0 \leq g_0(k) \leq f(k)$ for all $k \geq 0$. The lifetime utility yielded by this policy is
	\[w_0(k_0) = \sum_{t=0}^{\infty} \beta^t U\big( f(k_t) - g_0(k_t) \big).	\]
Notice that we can write the above equation as 
	\[w_0(k_0) = U\big( f(k_0) - g_0(k_0) \big)	+  \sum_{t=1}^{\infty} \beta^t U\big( f(k_t) - g_0(k_t) \big). \]
Now alter the indices in the summation to get 
	\[w_0(k_0) = U\big( f(k_0) - g_0(k_0) \big)	+  \beta \sum_{t=0}^{\infty} \beta^t U\big( f(k_{t+1}) - g_0(k_{t+1}) \big). \]
Because $g_0(k)=k_{t+1}$, the summation is now precisely $w_0\big(g_0(k)\big)$. Thus, we have
\begin{equation}
	w_0(k) = U\big( f(k) - g_0(k) \big)	+ \beta w_0\big(g_0(k)\big).  \label{guess1}
\end{equation}
	
Now suppose that $v_0=w_0$ is the initial guess for a value function. Then we will be considering the function $v_1$ defined as
	\[v_1(k) = \max_{0 \leq k' \leq f(k)} \left\{U \big( f(k) - k' \big) + \beta v_0(k') \right\}.	\]
Notice what's happening here -- we're allowed to pick \emph{any} feasible $k'$ in the initial period, but then we must follow $v_0$ which is defined in terms of $g_0$ for all subsequent periods. And in fact, $g_0(k)$ would be a feasible choice in the initial period. This means that $v_1(k)$ will do either as well as could have been done by also picking $k'=g_0(k)$ in the initial period, \emph{or better}. In the maths,
\begin{align*}
	 v_1(k) &=  \max_{0 \leq k' \leq f(k)} \left\{U \big( f(k) - k' \big) + \beta v_0(k') \right\}\\
	 		& \geq U\big( f(k) - g_0(k) \big) + \beta v_0\big(g_0(k)\big)\\
	 		& = v_0(k).
\end{align*}
Well okay, since $v_1(k) \geq v_0(k)$, it follows that
\begin{align*}
	v_2(k) &= \max_{0 \leq k' \leq f(k)} \left\{U \big( f(k) - k' \big) + \beta v_1(k') \right\} \\
		&\geq \max_{0 \leq k' \leq f(k)} \left\{U \big( f(k) - k' \big) + \beta v_0(k') \right\}\\
		&= v_1(k).
\end{align*}
And so on and so forth. So by induction, $v_{n+1}(k) \geq v_n(k)$ for all $k$. It sure would be nice if $\{v_n\}$ converged to a solution as $v$, no?

There is another, evidently more convenient, way of expressing the method of successive approximations. We have an operator $T:C \rightarrow C$ for some set $C$. Ultimately we want to find a function that satisfies $v = T(v)$ so that we have a fixed point. In particular, we can define a new function $T:\R_+ \rightarrow \R$ such that
	\[T\big( w(k) \big) = \max_{0 \leq k' \leq f(k)} \left\{ U\big(f(k) - k' \big)\right\} + \beta w(k').	\]
In essence, $w(\cdot)$ is the ``old'' value function approximation and $T\big( w(\cdot) \big)$ is the ``new'' value function approximation.



\section{Cobb-Douglas Approximations}

Let's just guess that $v_0(k)=0$. Seems like the most ``neutral'' guess. Then we find $v_1$ by solving
\begin{align*}
	v_1(k)	&=	\max_{0\leq k' \leq k^{\alpha}} \ln(k^{\alpha} - k') + \beta v_0(k') \\
		&= 	\max_{0\leq k' \leq k^{\alpha}} \ln(k^{\alpha} - k').
\end{align*}
Clearly this is maximized when $k'=0$, and thus $v_1(k)=\alpha \ln(k)$. 

Now let's do another iterate by solving 
\begin{align*}
	v_2(k)	&=	\max_{0\leq k' \leq k^{\alpha}} \ln(k^{\alpha} - k') + \beta v_1(k') \\
		&=	\max_{0\leq k' \leq k^{\alpha}} \ln(k^{\alpha} - k') + \beta \alpha \ln(k').
\end{align*}
This is concave over the maximizing interval so we can find the critical point  and plug it into the function. Doing so gives 
	\[v_2(k)=(\alpha + \alpha^2 \beta)\ln(k) - \ln \left( \frac{1 - \alpha \beta}{\alpha \beta} \right) - \alpha \beta \ln \left(1 - \alpha \beta \right).	\]
Let's just go ahead and say $v_2(k)=(\alpha + \alpha^2 \beta)\ln(k) + b_2$. 

We are not done yet, although we will stop iterating at a somewhat arbitrary point, that is, as soon as we ``see'' what's happening. Anyway, the third iterate is to solve  
\begin{align*}
	v_3(k)	&=	\max_{0\leq k' \leq k^{\alpha}} \ln(k^{\alpha} - k') + \beta v_2(k') \\
		&=	\max_{0\leq k' \leq k^{\alpha}} \ln(k^{\alpha} - k') + \beta \left[(\alpha + \alpha^2 \beta)\ln(k') + b_2 \right].
\end{align*}
Again, this is concave over the stated interval, so we can just find the critical point and plug it back into the function. Doing so gives, after a similar simplification as done above,
	\[v_3(k) = (\alpha + \alpha^2 \beta + \alpha^3  \beta^2)\ln(k) + b_3.	\]
I think this is enough to see what the pattern is going to be. To be specific,
\begin{align*}
	v_n(k)	&=	\alpha\left(1 + \alpha \beta + \alpha^2 \beta^2 + \hdots + \alpha^{n-1} \beta^{n-1}\right) \ln(k)  + b_n\\
			&=\left[\alpha \sum_{i=0}^{n-1} (\alpha \beta)^i \right] \ln(k) + b_n.
\end{align*}
Taking the limit as $n \rightarrow \infty$, we get
	\[v(k)=\frac{\alpha}{1 - \alpha \beta} \ln(k) + B = A\ln(k) +B.	\]
This is the same form as we found in equation (\ref{cobbvaluek_0}). If you are feeling masochistic, try to show that 
	\[B =  \frac{1}{1 - \beta}\left( \frac{\alpha \beta}{1 - \alpha \beta}\ln(\alpha \beta) + \ln(1 - \alpha \beta)	 \right).\]
I am certainly not going to -- I'm satisfied knowing that the same form emerges.\\

The interesting thing here is that we are searching for $v$, a \emph{function}, that solves the maximization problem. Usually we just want to find the maximizers of such a problem. In particular, we want to limit our attention to continuous functions. So one question is, given a continuous function $w$, how will we know that $T(w)$ is also continuous?  A second question is, is there an applicable fixed point theorem that works for the space of (continuous) functions? 






\end{document}
 
 	